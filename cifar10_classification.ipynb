{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Members:\n",
    "\n",
    "* Swaroop Bhandary K\n",
    "* Deepansh Pandey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        '''\n",
    "        inputs:                        \n",
    "            no_of_neurons_per_layer: an array defining the number of neurons in each layer\n",
    "                                     including input layer.\n",
    "                                     \n",
    "        description:\n",
    "            creates a network as defined by the variables. Applies relu activation after each\n",
    "            layer and uses softmax in the final layer. \n",
    "                                    \n",
    "        '''\n",
    "        \n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.layers = nn.ModuleList([nn.Linear(layers[i], layers[i + 1]) for i in range(len(layers) - 1)])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        '''\n",
    "        performs forward prop for the given input\n",
    "        '''\n",
    "       \n",
    "        out = x \n",
    "        for layer in self.layers:\n",
    "            out = self.relu(layer(out))          \n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# set device to cuda, if gpu is available\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    aDev = torch.device(\"cuda\")\n",
    "else:\n",
    "    aDev = torch.device(\"cpu\")  \n",
    "\n",
    "# load the dataset    \n",
    "\n",
    "train_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_dataset = dsets.CIFAR10(root='./data',\n",
    "                            train=True,\n",
    "                            transform=train_transforms,\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.CIFAR10(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)    \n",
    "\n",
    "CLASSES = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using grid search to find the best hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.001 hidden neuron: 100 batch: 32 accuracy: 31.950000762939453\n",
      "learning rate: 0.001 hidden neuron: 100 batch: 64 accuracy: 26.56999969482422\n",
      "learning rate: 0.001 hidden neuron: 100 batch: 128 accuracy: 22.809999465942383\n",
      "learning rate: 0.001 hidden neuron: 200 batch: 32 accuracy: 25.780000686645508\n",
      "learning rate: 0.001 hidden neuron: 200 batch: 64 accuracy: 20.81999969482422\n",
      "learning rate: 0.001 hidden neuron: 200 batch: 128 accuracy: 29.940000534057617\n",
      "learning rate: 0.001 hidden neuron: 300 batch: 32 accuracy: 14.890000343322754\n",
      "learning rate: 0.001 hidden neuron: 300 batch: 64 accuracy: 25.700000762939453\n",
      "learning rate: 0.001 hidden neuron: 300 batch: 128 accuracy: 30.5\n",
      "learning rate: 0.0005 hidden neuron: 100 batch: 32 accuracy: 33.650001525878906\n",
      "learning rate: 0.0005 hidden neuron: 100 batch: 64 accuracy: 26.229999542236328\n",
      "learning rate: 0.0005 hidden neuron: 100 batch: 128 accuracy: 25.040000915527344\n",
      "learning rate: 0.0005 hidden neuron: 200 batch: 32 accuracy: 29.799999237060547\n",
      "learning rate: 0.0005 hidden neuron: 200 batch: 64 accuracy: 25.219999313354492\n",
      "learning rate: 0.0005 hidden neuron: 200 batch: 128 accuracy: 24.979999542236328\n",
      "learning rate: 0.0005 hidden neuron: 300 batch: 32 accuracy: 15.899999618530273\n",
      "learning rate: 0.0005 hidden neuron: 300 batch: 64 accuracy: 29.510000228881836\n",
      "learning rate: 0.0005 hidden neuron: 300 batch: 128 accuracy: 24.170000076293945\n",
      "learning rate: 0.0001 hidden neuron: 100 batch: 32 accuracy: 29.709999084472656\n",
      "learning rate: 0.0001 hidden neuron: 100 batch: 64 accuracy: 23.739999771118164\n",
      "learning rate: 0.0001 hidden neuron: 100 batch: 128 accuracy: 25.780000686645508\n",
      "learning rate: 0.0001 hidden neuron: 200 batch: 32 accuracy: 27.040000915527344\n",
      "learning rate: 0.0001 hidden neuron: 200 batch: 64 accuracy: 25.420000076293945\n",
      "learning rate: 0.0001 hidden neuron: 200 batch: 128 accuracy: 25.200000762939453\n",
      "learning rate: 0.0001 hidden neuron: 300 batch: 32 accuracy: 28.139999389648438\n",
      "learning rate: 0.0001 hidden neuron: 300 batch: 64 accuracy: 30.690000534057617\n",
      "learning rate: 0.0001 hidden neuron: 300 batch: 128 accuracy: 28.709999084472656\n",
      "Grid search for hyperparameter tuning:\n",
      "[[[31.95000076 26.56999969 22.80999947]\n",
      "  [25.78000069 20.81999969 29.94000053]\n",
      "  [14.89000034 25.70000076 30.5       ]]\n",
      "\n",
      " [[33.65000153 26.22999954 25.04000092]\n",
      "  [29.79999924 25.21999931 24.97999954]\n",
      "  [15.89999962 29.51000023 24.17000008]]\n",
      "\n",
      " [[29.70999908 23.73999977 25.78000069]\n",
      "  [27.04000092 25.42000008 25.20000076]\n",
      "  [28.13999939 30.69000053 28.70999908]]]\n"
     ]
    }
   ],
   "source": [
    "# fixed values \n",
    "\n",
    "input_dim = 32*32*3\n",
    "output_dim = 10\n",
    "num_epochs = 10 \n",
    "\n",
    "\n",
    "# hyperparameters to tune\n",
    "learning_rates = [0.001, 0.0005, 0.0001]\n",
    "hidden_neurons = [100, 200, 300]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "accuracies = np.zeros([3,3,3])\n",
    "\n",
    "for lr_id, lr_val in enumerate(learning_rates):\n",
    "    for hn_id, hn_val in enumerate(hidden_neurons):\n",
    "        for b_id, b_val in enumerate(batch_sizes):\n",
    "\n",
    "            learning_rate = lr_val\n",
    "            batch_size = b_val\n",
    "            hidden_neuron = hn_val\n",
    "\n",
    "            layers = np.array([input_dim, hidden_neuron, output_dim])\n",
    "\n",
    "            criterion = nn.CrossEntropyLoss().to(aDev)\n",
    "\n",
    "            model = LogisticRegressionModel(layers)\n",
    "            model.to(aDev)\n",
    "            \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "            # make the dataset iterable\n",
    "            train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       shuffle=True)\n",
    "\n",
    "            test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                      batch_size=10000,\n",
    "                                                      shuffle=False)\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "                    images = images.view(-1, input_dim).to(aDev)\n",
    "                    labels = labels.to(aDev)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(images)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for images, labels in test_loader:\n",
    "\n",
    "                images = images.view(-1, input_dim).to(aDev) \n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                total += labels.size(0)         \n",
    "                correct += (predicted.cpu() == labels.cpu()).sum().float()\n",
    "            accuracy = 100. * correct / total\n",
    "\n",
    "            accuracies[lr_id, hn_id, b_id] = accuracy\n",
    "            print(\"learning rate: {0} hidden neuron: {1} batch: {2} accuracy: {3}\".format(lr_val, hn_val, \n",
    "                                                                                          b_val, accuracy))\n",
    "print(\"Grid search for hyperparameter tuning:\")\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We found that the best values for the hyperparameter values are as follows. We used grid search to get these values. \n",
    "\n",
    "* learning rate = 0.0005\n",
    "* batch_size = 32\n",
    "* hidden_neuron = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swaroop/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 30.219999313354492\n",
      "confusion matrix as shown below\n",
      "[[771   0  49  72   7  40   7   2  51   1]\n",
      " [402  73  17 115  32 136   6   6 161  52]\n",
      " [198   0 368 197  35 165  13   3  18   3]\n",
      " [115   1  97 469  15 259  18   1  21   4]\n",
      " [173   0 250 189 164 172  23   8  19   2]\n",
      " [ 78   0 104 321  16 438  16   4  20   3]\n",
      " [ 44   0 150 331  49 258 151   0  15   2]\n",
      " [269   0 153 218  51 189  21  78  18   3]\n",
      " [412   2  27  64   5  67   3   0 415   5]\n",
      " [398  12  50 210   6  93  11   2 123  95]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dim = 32*32*3\n",
    "output_dim = 10\n",
    "\n",
    "learning_rate = 0.0005\n",
    "batch_size = 32\n",
    "hidden_neuron = 100\n",
    "\n",
    "layers = np.array([input_dim, hidden_neuron, output_dim])\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(aDev)\n",
    "\n",
    "model = LogisticRegressionModel(layers)\n",
    "model.to(aDev)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "# make the dataset iterable\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=10000,\n",
    "                                          shuffle=False)\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, input_dim).to(aDev)\n",
    "        labels = labels.to(aDev)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images = images.view(-1, input_dim).to(aDev) \n",
    "    outputs = model(images)\n",
    "\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)         \n",
    "    correct += (predicted.cpu() == labels.cpu()).sum().float()\n",
    "\n",
    "accuracy = 100. * correct / total\n",
    "print(\"accuracy is {0}\".format(accuracy))\n",
    "print(\"confusion matrix as shown below\")\n",
    "print(confusion_matrix(labels.data.cpu().numpy(), predicted.data.cpu().numpy()))\n",
    "\n",
    "plt.title(\"Loss curve\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.plot(np.arange(len(loss_list)), loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_split(split_no, batch_size, k_fold=5):\n",
    "    \n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    train_dataset = dsets.CIFAR10(\n",
    "        root='./data', train=True,\n",
    "        download=True, transform=transform)\n",
    "\n",
    "    valid_dataset = dsets.CIFAR10(\n",
    "        root='./data', train=True,\n",
    "        download=True, transform=transform)\n",
    "\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    \n",
    "    # determines the number of samples in each splot\n",
    "    split = int(np.floor(num_train/k_fold))\n",
    "\n",
    "    # retains one part of the split for validation and the rest for training\n",
    "    valid_idx = indices[split_no*split:(split_no+1)*split]  \n",
    "    train_idx = np.array(list(filter(lambda x: x not in valid_idx, indices)))\n",
    "        \n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "    return (train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/swaroop/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "learning rate: 0.001 hidden neurons: 100 accuracy: 1.6040000915527344\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "learning rate: 0.001 hidden neurons: 200 accuracy: 1.4600000381469727\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "learning rate: 0.001 hidden neurons: 300 accuracy: 2.062000036239624\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "learning rate: 0.0005 hidden neurons: 100 accuracy: 1.805999994277954\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "learning rate: 0.0005 hidden neurons: 200 accuracy: 2.447999954223633\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "learning rate: 0.0005 hidden neurons: 300 accuracy: 1.8540000915527344\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "learning rate: 0.0001 hidden neurons: 100 accuracy: 1.7700001001358032\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "learning rate: 0.0001 hidden neurons: 200 accuracy: 1.8280000686645508\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "learning rate: 0.0001 hidden neurons: 300 accuracy: 1.4140000343322754\n"
     ]
    }
   ],
   "source": [
    "input_dim = 32*32*3\n",
    "output_dim = 10\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "\n",
    "# define number of folds\n",
    "kfolds = 5\n",
    "\n",
    "# hyperparameters to tune\n",
    "learning_rates = [0.001, 0.0005, 0.0001]\n",
    "hidden_neurons = [100, 200, 300]\n",
    "\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for hidden_neuron in hidden_neurons:\n",
    "        \n",
    "        layers = np.array([input_dim, hidden_neuron, output_dim])\n",
    "        criterion = nn.CrossEntropyLoss().to(aDev)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        model = LogisticRegressionModel(layers)\n",
    "        model.to(aDev)\n",
    "\n",
    "        for split_no in range(5):\n",
    "            train_loader, val_loader = get_train_val_split(split_no, batch_size, kfolds)\n",
    "            accuracy = 0\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "                    images = images.view(-1, input_dim).to(aDev)\n",
    "                    labels = labels.to(aDev)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(images)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    loss_list.append(loss.item())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            for images, labels in val_loader:\n",
    "                images = images.view(-1, input_dim).to(aDev) \n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)         \n",
    "                correct += (predicted.cpu() == labels.cpu()).sum().float()\n",
    "\n",
    "            accuracy += 100. * correct / total\n",
    "        \n",
    "        print(\"learning rate: {0} hidden neurons: {1} accuracy: {2}\".format(learning_rate, hidden_neuron,\n",
    "                                                                            accuracy/kfolds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the accuracy values, there is an issue with the implementation of the kfold validation. We were not able to pin point the exact issue as we implemented it at the end and did not have enough time to debug it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference:\n",
    "\n",
    "* https://gist.github.com/kevinzakka/d33bf8d6c7f06a9d8c76d97a7879f5cb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
